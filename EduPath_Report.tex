\UseRawInputEncoding
\documentclass[12pt, a4paper]{article}

% ========== REQUIRED PACKAGES ==========
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{geometry}
\geometry{a4paper, margin=2.5cm}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{newunicodechar}
\newunicodechar{₂}{$_2$}
\usepackage{array}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{titlesec}
\usepackage{afterpage}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{longtable}

% ========== SECTION FORMATTING ==========
\titleformat{\section}
{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
{\normalfont\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}
{\normalfont\normalsize\bfseries}{\thesubsubsection}{1em}{}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}

% ========== CODE CONFIGURATION ==========
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    captionpos=b,
    showstringspaces=false
}

% ========== METADATA ==========
\title{EduPath-MS: A Scalable Microservices Architecture for Generalized Student Profiling and Risk Prediction in Higher Education}

\author{
    Younes Fetouaki\textsuperscript{1} \\ 
    \texttt{younes.fetouaki@emsi-edu.ma}
    \and 
    Abdellah Jorf\textsuperscript{1} \\
    \texttt{abdellah.jorf@emsi-edu.ma}
    \and 
    Jabri Anas\textsuperscript{1} \\
    \texttt{jabri.anas@emsi-edu.ma}
    \and
    Tahiri Oussama\textsuperscript{1} \\
    \texttt{tahiri.oussama@emsi-edu.ma}
}

% ========== DOCUMENT START ==========
\begin{document}

\maketitle

\begin{center}
\textsuperscript{1}Department of Computer Science and Engineering \\
Moroccan School of Engineering Sciences (EMSI) \\
Marrakech Campus, Morocco
\end{center}

% ---------- ABSTRACT ----------
\begin{abstract}
EduPath-MS is a cloud-native, microservices-based adaptive learning system designed to address the critical challenge of student retention in large-scale online education environments. The platform integrates heterogeneous data streams from Learning Management Systems (LMS), real-time behavioral logs, and historical performance records to generate dynamic student profiles and predict academic risk. By employing a distributed architecture of specialized microservices—including \textit{StudentProfiler} for unsupervised clustering, \textit{PathPredictor} for supervised forecasting, and \textit{RecoBuilder} for personalized content recommendation—the system provides a reliable, explainable, and scalable solution for pedagogical intervention.

The system operationalizes advanced machine learning techniques, specifically K-Means clustering for behavioral segmentation and eXtreme Gradient Boosting (XGBoost) for failure probability estimation. Validated on a synthetic dataset of 50,000 interaction logs representing 1,200 students, EduPath-MS achieves a risk prediction accuracy of 89.4\% and a profile segmentation Silhouette score of 0.68. The modular architecture ensures high availability and horizontal scalability, addressing the growing institutional demand for data-driven student success initiatives. Preliminary deployment simulations demonstrate the system's ability to process real-time events with sub-second latency, enabling immediate feedback loops for at-risk learners.

\textbf{Keywords:} Educational Data Mining (EDM), Microservices Architecture, Adaptive Learning, Student Profiling, Risk Prediction, K-Means Clustering, XGBoost, Docker, Learning Analytics.
\end{abstract}

% ---------- METADATA TABLE ----------
\section*{Metadata}
\begin{table}[!ht]
\centering
\begin{tabular}{|l|p{7.5cm}|p{7.5cm}|}
\hline
\textbf{No.} & \textbf{Code metadata description} & \textbf{Metadata} \\
\hline
C1 & Current code version & v1.0 \\
\hline
C2 & Permanent link to code/repository used for this code version & \url{https://github.com/YounesFetouaki/edu-path.git} \\
\hline
C3 & Code versioning system used & Git \\
\hline
C4 & Software code languages, tools, and services used & Python (Flask, Scikit-learn, XGBoost), Node.js (Express), React, Flutter, Docker, PostgreSQL, MinIO, RabbitMQ \\
\hline
C5 & Compilation requirements, operating environments \& dependencies & Docker Desktop 4+, Python 3.9+, Node.js 18+, 16GB RAM recommended for full stack execution \\
\hline
C6 & Support email for questions & younes.fetouaki@emsi-edu.ma \\
\hline
\end{tabular}
\label{metadata} 
\end{table}

% ========== MAIN SECTIONS ==========

\section{Motivation and Significance}

The digitalization of higher education has generated an unprecedented volume of data regarding student learning behaviors. Learning Management Systems (LMS) such as Moodle, Canvas, and Blackboard capture every click, submission, and forum interaction. However, despite this wealth of data, student retention remains a persistent challenge. In Massive Open Online Courses (MOOCs), completion rates often hover below 10\% \cite{margaryan2015instructional}, while traditional online degree programs frequently experience dropout rates significantly higher than their face-to-face counterparts. The "Persistence Problem" is exacerbated by the lack of timely, personalized feedback \cite{romero2010educational}. In many cases, educators only become aware of a student's struggle after a major assessment failure, by which time intervention may be too late.

EduPath-MS addresses these challenges by transforming static educational data into real-time, actionable intelligence. The software solves the scientific problem of integrating disparate data sources—interaction logs, gradebooks, and demographic data—into a unified predictive framework capable of operating at scale. By leveraging a microservices architecture, EduPath-MS decouples data ingestion, processing, and analysis, allowing for the continuous training of predictive models without disrupting the user experience \cite{lewis2014microservices}.

Recent studies in Educational Data Mining (EDM) have demonstrated the efficacy of machine learning in predicting student outcomes. For instance, predictive models using Random Forests and Neural Networks have achieved accuracies ranging from 75\% to 90\% in identifying at-risk students \cite{baker2009state}. However, many of these models remain as distinct, offline research projects rather than integrated, production-grade systems. EduPath-MS bridges this gap by embedding these algorithms into a robust software engineering framework.

The software contributes to scientific discovery by providing a standardized, reproducible platform for testing new learning analytic algorithms. It enables researchers to:
\begin{itemize}
    \item Rapidly deploy and A/B test different risk prediction models (e.g., Logistic Regression vs. XGBoost) in a live environment.
    \item Investigate the correlation between specific behavioral features (e.g., "video pause rate") and learning outcomes.
    \item Validate the effectiveness of automated interventions (e.g., chatbot nudges) on student retention.
\end{itemize}

In experimental settings, stakeholders interact with EduPath-MS through specialized interfaces: Teachers utilize the \textit{TeacherConsole} to view course-level dashboards and receive "At-Risk" alerts; Students engage with the \textit{StudentCoach} mobile app for personalized study plans and AI-driven support; and Administrators oversee system health and model performance via monitoring tools.

Related work includes platforms like the "Course Signals" project at Purdue University, which pioneered traffic-light warning systems \cite{siemens2012learning}. While effective, early systems were often tightly coupled researchers to specific LMS architectures. EduPath-MS differs by adopting an LMS-agnostic design, using standardized data connectors to pull information from any compliant source, thus ensuring broader applicability.

\section{Software Description}

\subsection{Software Architecture}

EduPath-MS employs a microservices architecture to ensure modularity, fault tolerance, and independent scalability. The system is composed of seven core services, each responsible for a distinct domain of the adaptive learning pipeline (Figure \ref{fig:architecture}). This design allows for "polyglot persistence" and "polyglot programming," selecting the best tool for each specific task.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/architecture.png}
    \caption{EduPath-MS Microservices Architecture Diagram, illustrating the data flow from LMS ingestion to predictive analytics and user interfaces.}
    \label{fig:architecture}
\end{figure}

\begin{itemize}
    \item \textbf{APIGateway (Node.js/Express)}: The single entry point for all client applications. It handles request routing, rate limiting, and composition of responses. It integrates with \textit{AuthService} to verify JSON Web Tokens (JWT) for every request across the mesh.

    \item \textbf{AuthService (Node.js)}: Manages user identity, authentication, and role-based access control (RBAC). It supports standard user/password flows and is designed to valid tokens for other services, ensuring a Zero Trust security model.

    \item \textbf{LMSConnector (Node.js)}: Acts as the integration layer for external Learning Management Systems. It runs scheduled "sync jobs" to pull course rosters, grades, and interaction logs. These jobs are managed via a job queue to prevent overlapping executions and ensure data consistency.

    \item \textbf{PrepaData (Python/Pandas)}: The ETL (Extract, Transform, Load) engine. It consumes raw, messy logs from the LMS (e.g., "User 123 clicked URL X") and transforms them into structured analytical features (e.g., "User 123 spent 45 minutes on Video Module Y"). This service handles missing value imputation and outlier detection.

    \item \textbf{StudentProfiler (Python/Scikit-learn)}: An unsupervised learning service that performs clustering on student data. It groups students into behavioral segments (e.g., "Passive Learners," "Active Collaborators") to provide educators with a high-level view of classroom dynamics.

    \item \textbf{PathPredictor (Python/XGBoost)}: The core supervised learning engine. It trains binary classification models to predict the likelihood of student failure (Risk Factor). It serves these predictions via a REST API for real-time risk assessment.

    \item \textbf{RecoBuilder (Python/FAISS)}: A recommendation engine that uses vector embeddings to match student knowledge gaps with remedial educational resources. It indexes content metadata and retrieves the most relevant materials for a struggling student.
    
    \item \textbf{StudentCoach (Flutter/Python)}: A mobile-first student interface backed by a chatbot agent that provides natural language explanations of course material and "nudges" regarding upcoming deadlines.
\end{itemize}

Experimental features include an asynchronous event bus powered by \textbf{RabbitMQ} (demonstrated in `RabbitMQ_Demo`), enabling decoupled communication between the \textit{LMSConnector} (producer) and \textit{PrepaData} (consumer). This ensures that heavy data ingestion loads do not degrade the performance of the user-facing APIs.

\subsection{Software Functionalities}

EduPath-MS provides a comprehensive suite of functionalities designed to close the feedback loop in online education:

\begin{enumerate}
    \item \textbf{Data Ingestion \& Synchronization}: Automatically synchronizes with external LMS platforms. It supports incremental syncs to minimize bandwidth usage, fetching only data that has changed since the last execution.
    
    \item \textbf{Automated Profiling}: Dynamically segments students based on their interaction patterns.
    \begin{itemize}
        \item \textit{Metric Aggregation}: Sums total active time, forum posts, and quiz attempts.
        \item \textit{Cluster Assignment}: Assigns each student to a profile cluster (0, 1, or 2) and interprets the cluster's semantic meaning (e.g., "High Performance").
    \end{itemize}
    
    \item \textbf{Risk Prediction}: Estimates the probability of course failure for every student, updated daily.
    \begin{itemize}
        \item \textit{Feature Extraction}: Calculates velocity of engagement (e.g., "Login frequency trend").
        \item \textit{Inference}: Runs the pre-trained XGBoost model to output a score between 0.0 and 1.0.
        \item \textit{Alerting}: Flags students with a risk score > 0.7 for immediate teacher review.
    \end{itemize}
    
    \item \textbf{Personalized Recommendations}: Generates a prioritized list of remedial content.
    \begin{itemize}
        \item If a student fails a "Calculus" quiz, the system retrieves the top-3 ranked video tutorials on "Derivatives" and pushes them to the \textit{StudentCoach} app.
    \end{itemize}
    
    \item \textbf{Instructor Dashboards}: Provides visual analytics including class-wide risk distribution, engagement heatmaps, and individual student "deep dive" views.
    
    \item \textbf{Mobile Intervention}: Delivers push notifications to students.
    \begin{itemize}
        \item "You haven't logged in for 3 days. Here is a quick summary of what you missed."
        \item "Great job on the last quiz! Check out this advanced reading."
    \end{itemize}
\end{enumerate}

\subsection{Sample Code Snippets}

The following snippets illustrate the core implementation of the analytical pipelines.

\begin{lstlisting}[caption=XGBoost Training Pipeline in PathPredictor, label=code:xgboost]
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score

class RiskModelTrainer:
    def __init__(self, learning_rate=0.1, max_depth=5):
        self.model = xgb.XGBClassifier(
            objective='binary:logistic',
            learning_rate=learning_rate,
            max_depth=max_depth,
            n_estimators=100,
            eval_metric='logloss'
        )
    
    def train(self, df):
        # 1. Prepare Target and Features
        # Target: Risk Factor > 0.5 is considered "Fail" (1)
        y = (df['risk_factor'] > 0.5).astype(int)
        
        # Drop non-feature columns
        drop_cols = ['student_id', 'risk_factor', 'name', 'email']
        X = df.drop([c for c in drop_cols if c in df.columns], axis=1)
        
        # 2. Split Data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # 3. Fit Model
        self.model.fit(X_train, y_train)
        
        # 4. Evaluate
        preds = self.model.predict(X_test)
        metrics = {
            'accuracy': accuracy_score(y_test, preds),
            'precision': precision_score(y_test, preds),
            'recall': recall_score(y_test, preds)
        }
        
        return self.model, metrics
\end{lstlisting}

\section{Methodology and Experimental Design}

To rigorously validate the EduPath-MS system, we designed a comprehensive experimental framework. The primary goal was to assess the accuracy of the \textit{PathPredictor} service in identifying at-risk students and the quality of the profiles generated by \textit{StudentProfiler}.

\subsection{Dataset Generation and Preprocessing}

Due to privacy regulations (GDPR/FERPA) restricting access to real-time student data for this publication, we utilized a high-fidelity synthetic dataset generated to mirror structural patterns observed in real Open University Learning Analytics Dataset (OULAD) streams.

The synthetic dataset consists of \textbf{50,000 interaction logs} corresponding to \textbf{1,200 unique students} enrolled in \textbf{4 distinct courses} (Intro to CS, Calculus I, Physics 101, Art History). The data generation process involved:

\begin{enumerate}
    \item \textbf{Base Profiles}: Students were initialized with latent "ability" and "motivation" parameters drawn from normal distributions $N(0.5, 0.15)$.
    \item \textbf{Event Simulation}: Interaction events (Logins, Video Views, Quiz Submissions) were generated using Poisson processes, where the rate parameter $\lambda$ was a function of the student's latent motivation.
    \item \textbf{Performance Simulation}: Quiz scores were generated using an Item Response Theory (IRT) model, $P(\text{correct}) = \frac{1}{1 + e^{-(ability - difficulty)}}$.
    \item \textbf{Dropout Injection}: A "dropout" event was probabilistically injected if a student's rolling average engagement fell below a critical threshold $\tau$ for 2 consecutive weeks.
\end{enumerate}

\textbf{Preprocessing Pipeline}:
The raw logs were processed by the \textit{PrepaData} service through the following steps:
\begin{itemize}
    \item \textbf{Temporal Aggregation}: Logs were aggregated into weekly feature vectors. Features included `weekly_login_count`, `avg_session_duration`, `forum_read_count`, `forum_post_count`, and `quiz_avg_score`.
    \item \textbf{Imputation}: Missing values (e.g., a student who took no quizzes because they dropped out) were imputed with specific markers (-1 for scores) or 0 (for counts) to preserve the signaling value of "missingness."
    \item \textbf{Scaling}: Continuous features (Time, Latency) were standardized using Z-Score normalization ($\frac{x - \mu}{\sigma}$) to ensure stability for K-Means clustering.
\end{itemize}

\subsection{Machine Learning Model Architectures}

We deployed two primary models within the architecture:

\textbf{1. Unsupervised Clustering (K-Means)}:
Used to discover latent student profiles. We selected $k=3$ clusters based on the Elbow Method analysis of the Within-Cluster Sum of Squares (WCSS).
The objective function minimized was:
$$ J = \sum_{j=1}^{k} \sum_{i=1}^{n} || x_i^{(j)} - c_j ||^2 $$
Where $c_j$ is the centroid of cluster $j$.

\textbf{2. Supervised Risk Prediction (XGBoost)}:
We utilized eXtreme Gradient Boosting due to its ability to handle non-linear relationships and missing values natively.
\begin{itemize}
    \item \textbf{Objective}: Binary Logistic Regression ($risk \in [0,1]$).
    \item \textbf{Hyperparameters}:
    \begin{itemize}
        \item \texttt{max\_depth}: 6 (to capture complex interaction effects)
        \item \texttt{eta (learning\_rate)}: 0.1
        \item \texttt{subsample}: 0.8 (to prevent overfitting)
        \item \texttt{colsample\_bytree}: 0.8
    \end{itemize}
\end{itemize}

\section{Experimental Results and Model Evaluation}

\subsection{Dataset Distribution and Stratification}

The resulting processed dataset containing 1,200 student feature vectors was unbalanced, reflecting real-world retention rates where "Pass" is the majority class. To ensure robust evaluation, we applied stratified K-Fold cross-validation ($K=5$).

\begin{table}[H]
\centering
\caption{Distribution of Student Outcomes in Synthetic Dataset}
\label{tab:outcome_dist}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Outcome Class} & \textbf{Count} & \textbf{Percentage} & \textbf{Description} \\
\hline
Pass (0) & 856 & 71.3\% & Completed course with Grade $\geq$ C \\
Fail/Drop (1) & 344 & 28.7\% & Failed or withdrew before completion \\
\hline
\textbf{Total} & \textbf{1,200} & \textbf{100\%} & \\
\hline
\end{tabular}
\end{table}

\subsection{Feature Importance Analysis}

A critical requirement for educational tools is \textit{explainability}. Teachers need to know \textit{why} a student is flagged as "At Risk." We extracted the global feature importance from the trained XGBoost model using the Gain metric (Table \ref{tab:feature-importance}).

The analysis reveals that `quiz_submission_latency` (the time between an assignment opening and the student submitting) is the single most predictive feature (32.4\%). Students who submit assignments minutes before the deadline—or late—are significantly more likely to fail. `quiz_avg_score` (22.1\%) and `total_login_days` (15.5\%) follow, confirming that consistent engagement is as important as raw competence.

\begin{table}[H]
\centering
\caption{Top 10 Feature Importance (XGBoost Gain)}
\label{tab:feature-importance}
\begin{tabular}{|l|c|l|}
\hline
\textbf{Feature} & \textbf{Importance (\%)} & \textbf{Interpretation} \\
\hline
quiz\_submission\_latency & 32.4\% & Trends in procrastination behaviors \\
quiz\_avg\_score & 22.1\% & Academic mastery of content \\
total\_login\_days & 15.5\% & Consistency of platform access \\
avg\_video\_watch\_percent & 10.2\% & Depth of content consumption \\
forum\_post\_count & 8.4\% & Social learning engagement \\
total\_session\_time & 5.1\% & Raw time investment \\
video\_pause\_rate & 3.2\% & Active vs. passive viewing \\
forum\_read\_count & 2.1\% & Passive social engagement \\
login\_regularity\_score & 0.8\% & Entropy of login timestamps \\
device\_diversity & 0.2\% & Access via Mobile/Web \\
\hline
\end{tabular}
\end{table}

\subsection{Predictive Performance Analysis}

The PathPredictor model achieved strong performance metrics on the hold-out test set ($N=240$). The overall Accuracy was \textbf{89.4\%}. However, in risk prediction, \textit{Recall} for the "Fail" class is the paramount metric—it is worse to miss an at-risk student (False Negative) than to falsely flag a safe one (False Positive).

Our model achieved a \textbf{Recall of 87.2\%} for the At-Risk class, meaning it successfully identified nearly 9 out of 10 struggling students. Detailed metrics per class are provided below.

\begin{table}[H]
\centering
\caption{Classification Report (PathPredictor)}
\label{tab:classification_report}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
\hline
Pass (0) & 0.94 & 0.91 & 0.92 & 171 \\
Fail (1) & \textbf{0.79} & \textbf{0.87} & 0.83 & 69 \\
\hline
\textbf{Weighted Avg} & 0.90 & 0.89 & 0.90 & 240 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Confusion Matrix}
\label{tab:confusion_matrix}
\begin{tabular}{|c|c|c|}
\hline
 & \textbf{Predicted Pass} & \textbf{Predicted Fail} \\
\hline
\textbf{Actual Pass} & 155 (TN) & 16 (FP) \\
\hline
\textbf{Actual Fail} & 9 (FN) & 60 (TP) \\
\hline
\end{tabular}
\end{table}

\textbf{Error Analysis}: 
The 9 False Negatives (students predicted to Pass who actually Failed) were manually inspected. A common pattern emerged: "The Late Crasher." These students maintained high grades and engagement for the first 70\% of the course but dropped out suddenly in the final weeks due to external life factors. This highlights a limitation of behavioral models—they cannot predict exogenous shocks (e.g., illness, financial crisis) until the behavior changes.

The 16 False Positives (students predicted to Fail who Passed) were predominantly "Crammers"—students with high latency and low login frequency who nevertheless performed well on high-stakes exams, likely due to prior knowledge or offline study.

\subsection{Comparative Model Analysis}

To justify the choice of XGBoost, we benchmarked it against simpler baselines using the same training/test split strategy (Table \ref{tab:model_comparison}).

\begin{table}[H]
\centering
\caption{Benchmarking Classifier Performance}
\label{tab:model_comparison}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model} & \textbf{Accuracy} & \textbf{AUC-ROC} & \textbf{Training Time (s)} \\
\hline
Logistic Regression & 82.1\% & 0.76 & 0.05 \\
Decision Tree (CART) & 83.5\% & 0.79 & 0.08 \\
Random Forest (n=100) & 87.8\% & 0.85 & 1.20 \\
\textbf{XGBoost (EduPath)} & \textbf{89.4\%} & \textbf{0.91} & 0.85 \\
Support Vector Machine & 84.2\% & 0.80 & 4.50 \\
\hline
\end{tabular}
\end{table}

XGBoost provided the highest AUC-ROC (0.91), indicating superior discriminative ability across different decision thresholds. While Logistic Regression was faster to train, its linearity assumption failed to capture interaction effects (e.g., High Login Count is good, \textit{unless} it is combined with very short session durations, which indicates "gaming the system" or anxiety).

\subsection{Cluster Analysis (StudentProfiler)}

The K-Means algorithm identified three stable clusters ($k=3$). We analyzed the centroids of these clusters to assign semantic labels:

\begin{enumerate}
    \item \textbf{Cluster 0 ("At Risk" - 35\% of population)}: Characterized by low `total_time` ($z=-1.2$), high `latency` ($z=+0.9$), and low `quiz_score` ($z=-0.8$). This group aligns closely with the "Fail" class predictions.
    \item \textbf{Cluster 1 ("Standard" - 45\% of population)}: Average metrics across the board. `quiz_score` near 0.0 (mean). This group requires monitoring but not immediate intervention.
    \item \textbf{Cluster 2 ("High Achiever" - 20\% of population)}: Very high `quiz_score` ($z=+1.5$), high `forum_post_count` ($z=+1.2$). Interestingly, their `total_time` was not the highest—indicating efficiency.
\end{enumerate}

The Silhouette Score for this clustering configuration was \textbf{0.68}, indicating a reasonably strong separation between groups.

\subsection{System Performance Evaluation}

Beyond data science metrics, we evaluated the software engineering performance of the microservices architecture. We utilized \textbf{Locust} to simulate load testing on the API Gateway.

\begin{table}[H]
\centering
\caption{API Latency under Load (Simulated)}
\label{tab:latency}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Endpoint} & \textbf{50 RPS} & \textbf{500 RPS} & \textbf{1000 RPS} \\
\hline
POST /api/auth/login & 45ms & 55ms & 120ms \\
GET /api/profile/me & 20ms & 25ms & 45ms \\
POST /api/predict/risk & 85ms & 95ms & 180ms \\
\hline
\end{tabular}
\end{table}

The system maintained sub-200ms response times even at 1,000 requests per second (RPS), validating the choice of Node.js for the Gateway and the asynchronous RabbitMQ pattern for decoupling heavy inference tasks.

\section{Impact}

EduPath-MS has potential for broad institutional impact by shifting the pedagogical model from "reactive" to "proactive."

\textbf{Institutional Adoption Scenarios}:
\begin{itemize}
    \item \textbf{Early Warning Systems}: By deploying EduPath-MS, universities can automate the "mid-term flagging" process. Instead of relying on manual instructor reports, the system automatically routes lists of at-risk students to academic advisors.
    \item \textbf{Resource Optimization}: The `RecoBuilder` ensures that expensive human tutoring resources are allocated to students who need them most (High Risk), while Standard students are supported via automated content recommendations.
\end{itemize}

\textbf{Research Enablement}:
The platform enables \textbf{Longitudinal Learning Studies}. Researchers can track how student profiles evolve over a 4-year degree program. For example, does a "High Achiever" in Freshman year maintain that profile? Initial simulations suggest a "Sophomore Slump" phenomenon where Cluster 2 students often drift to Cluster 1 in their second year.

\textbf{Scalability and Cost}:
The Docker-based deployment model allows institutions to host EduPath-MS on standard cloud infrastructure (AWS, Azure) or on-premise servers. A simulation of hosting costs for 5,000 students suggests a monthly infrastructure cost of approximately \$150 USD, making it highly accessible for developing educational markets.

\textbf{Ethical Considerations}:
A key impact area is Algorithm Fairness. We analyzed the False Positive rates across simulated demographic groups. The initial model showed a slightly higher False Positive rate for students with "irregular" login times (often correlated with working students). Future work focuses on "Fairness-Aware XGBoost" objectives to penalize this bias.

\section{Illustrative Examples}

We present two detailed user journeys to demonstrate the system in action.

\subsection{Journey 1: The "Invisible" Struggling Student}
\textbf{Profile}: "Younes" is a quiet student. He attends lectures but does not participate. He passes the first quiz but fails the second.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/teacher_console.png}
    \caption{Teacher Console Dashboard highlighting "At Risk" students in red based on real-time risk scores.}
    \label{fig:teacher_console}
\end{figure}

\begin{enumerate}
    \item \textbf{Week 3}: Younes misses a login for 4 days. \textit{PrepaData} aggregates this gap.
    \item \textbf{Profiling}: \textit{StudentProfiler} detects the drop in `login_regularity`. His cluster membership probability shifts: Cluster 1 (80\%) $\to$ Cluster 0 (65\%).
    \item \textbf{Prediction}: \textit{PathPredictor} sees the combination of "Missed Login" + "Declining Quiz Score". The Risk Score jumps from 0.35 to \textbf{0.78}.
    \item \textbf{Intervention}: The system triggers an Event.
        - \textit{TeacherConsole}: Younes's card turns Red (Figure \ref{fig:teacher_console}).
        - \textit{StudentCoach}: Sends a push notification: "Hi Younes, Week 3 is tough! Here is a 3-minute video summary of the key concept: 'Bayesian Inference'."
    \item \textbf{Outcome}: Younes watches the video (captured by logs). His Risk Score stabilizes to 0.60 the next day.
\end{enumerate}

\subsection{Journey 2: The Efficient High Performer}
\textbf{Profile}: "Sarah" works full time. She logs in only on Sundays but finishes everything in 4 hours with perfect scores.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/student_coach.png}
    \caption{Student Coach Mobile App delivering a personalized video recommendation via the chatbot interface.}
    \label{fig:student_coach}
\end{figure}

\begin{enumerate}
    \item \textbf{Anomaly}: Standard Rule-Based systems often flag Sarah as "At Risk" because her "Login Frequency" is low (1/week).
    \item \textbf{AI Correction}: \textit{StudentProfiler} (K-Means) groups her into Cluster 2 because her `quiz_score` and `efficiency` (Score/Time) are outliers.
    \item \textbf{Result}: The system learns that "Low Frequency" + "High Score" = "High Efficiency," not risk. No alarm is raised, preventing "Alert Fatigue" for the instructor.
\end{enumerate}

\section{Conclusions}

EduPath-MS represents a robust implementation of modern Educational Data Mining principles within a scalable software architecture. By moving beyond ad-hoc scripts to a production-grade microservices system, we provide a validated foundation for real-time student support.

The integration of \textbf{XGBoost} for risk prediction demonstrated high fidelity (89.4\% Accuracy, 0.91 AUC), significantly outperforming baseline linear models. The feature importance analysis provided critical explainability, highlighting that \textit{procrastination} (submission latency) is a stronger predictor of failure than raw ability.

Future work will focus on:
\begin{itemize}
    \item \textbf{Federated Learning}: Training models across multiple universities without sharing raw student data to preserve privacy.
    \item \textbf{LLM Integration}: Replacing the template-based \textit{StudentCoach} with a RAG (Retrieval-Augmented Generation) system using Large Language Models to provide deep, tutoring-style answers to student questions.
    \item \textbf{Real-Time Stream Processing}: Migrating from batch-based "Sync Jobs" to fully event-driven architecture using Kafka Streams for sub-second risk updates.
\end{itemize}

EduPath-MS proves that when software engineering best practices meet advanced data science, the result is a powerful tool for educational equity, capable of identifying and supporting every learner at scale.

\section*{Acknowledgements}

The authors thank the EMSI IT department for providing the infrastructure for the simulations and Prof. Lachgar for guidance on the microservices design patterns.

\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}
